{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/ice1/5/4/arothe6/CS_7643_project\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %pip install imageio[ffmpeg]\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from model1 import Model1\n",
    "from model_simple import ModelSimple\n",
    "from endovis_dataset import EndovisDataset\n",
    "from reformat_data import convert_all_data\n",
    "\n",
    "segmentation_model_weights_path = \"model1_weights.pth\"\n",
    "tracking_model_weights_path = \"tracking_model_weights.pth\"\n",
    "\n",
    "og_data_path = r\"original_data\"\n",
    "data_path = r\"data\"\n",
    "\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_data/segmentation_train/Training/Dataset2/Video1.avi\n",
      "original_data/segmentation_train/Training/Dataset2/Segmentation1.avi\n",
      "original_data/segmentation_train/Training/Dataset3/Video1.avi\n",
      "original_data/segmentation_train/Training/Dataset3/Segmentation1.avi\n",
      "original_data/segmentation_train/Training/Dataset1/Video1.avi\n",
      "original_data/segmentation_train/Training/Dataset1/Left_Instrument_Segmentation1.avi\n",
      "original_data/segmentation_train/Training/Dataset1/Right_Instrument_Segmentation1.avi\n",
      "original_data/segmentation_train/Training/Dataset4/Video1.avi\n",
      "original_data/segmentation_train/Training/Dataset4/Segmentation1.avi\n",
      "original_data/segmentation_test/Dataset5/Video1.avi\n",
      "original_data/segmentation_test/Dataset5/Left_Instrument_Segmentation1.avi\n",
      "original_data/segmentation_test/Dataset5/Right_Instrument_Segmentation1.avi\n",
      "original_data/segmentation_test/Dataset2/Video1.avi\n",
      "original_data/segmentation_test/Dataset2/Segmentation1.avi\n",
      "original_data/segmentation_test/Dataset3/Video1.avi\n",
      "original_data/segmentation_test/Dataset3/Segmentation1.avi\n",
      "original_data/segmentation_test/Dataset6/Video1.avi\n",
      "original_data/segmentation_test/Dataset6/Segmentation1.avi\n",
      "original_data/segmentation_test/Dataset1/Video1.avi\n",
      "original_data/segmentation_test/Dataset1/Left_Instrument_Segmentation1.avi\n",
      "original_data/segmentation_test/Dataset1/Right_Instrument_Segmentation1.avi\n",
      "original_data/segmentation_test/Dataset4/Video1.avi\n",
      "original_data/segmentation_test/Dataset4/Segmentation1.avi\n",
      "original_data/tracking_train/Training/Dataset2/Video1.avi\n",
      "original_data/tracking_train/Training/Dataset3/Video1.avi\n",
      "original_data/tracking_train/Training/Dataset1/Video1.avi\n",
      "original_data/tracking_train/Training/Dataset4/Video1.avi\n",
      "original_data/tracking_test/Dataset5/Video1.avi\n",
      "original_data/tracking_test/Dataset2/Video1.avi\n",
      "original_data/tracking_test/Dataset3/Video1.avi\n",
      "original_data/tracking_test/Dataset6/Video1.avi\n",
      "original_data/tracking_test/Dataset1/Video1.avi\n",
      "original_data/tracking_test/Dataset4/Video1.avi\n"
     ]
    }
   ],
   "source": [
    "# Converts all the data from video to npz files\n",
    "# Only need to run this once when setting up your system\n",
    "# It will probably take 10 minutes to run; be patient :)\n",
    "\n",
    "# Subfolders where data is; True indicates it is segmentation data\n",
    "subfolders = { \n",
    "    \"segmentation_train\": True,\n",
    "    \"segmentation_test\": True,\n",
    "    \"tracking_train\": False,\n",
    "    \"tracking_test\": False\n",
    "}\n",
    "convert_all_data(og_data_path, data_path, subfolders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "torch.Size([16, 3, 576, 720])\n",
      "torch.Size([16, 64, 576, 720])\n"
     ]
    }
   ],
   "source": [
    "# Training for Segmentation\n",
    "\n",
    "# Hyperparameters \n",
    "# TODO tune these! I just made them randomly\n",
    "batch_size = 16\n",
    "learning_rate = 0.0001\n",
    "momentum = 0.9\n",
    "epochs = 10\n",
    "\n",
    "# Model\n",
    "model = ModelSimple() # Switch out with whichever model you like\n",
    "\n",
    "folder = os.path.join(data_path, \"segmentation_train\")\n",
    "dataset = EndovisDataset(folder)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True) # TODO can tune batch size\n",
    "\n",
    "criterion = nn.BCELoss() # Because https://medium.com/@kitkat73275/multi-label-classification-8d8ae55e8373#:~:text=For%20multi%2Dlabel%20classification%20with,class%20labels%20for%20new%20instances.\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum) # TODO tune these hyperparameters\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch %d:\" % epoch)\n",
    "    for frames, truths in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(frames)\n",
    "        loss = criterion(outputs, truths)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(\"    Loss: %f\" % loss.item())\n",
    "\n",
    "torch.save(model.state_dict(), segmentation_model_weights_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing for Segmentation\n",
    "\n",
    "model = Model1()\n",
    "model.load_state_dict(torch.load(segmentation_model_weights_path))\n",
    "model.eval()\n",
    "\n",
    "test_folder = r\"data\\segmentation_test\"\n",
    "testset = EndovisDataset(test_folder)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=True) \n",
    "\n",
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    for frames, truths in testloader:\n",
    "        outputs = torch.sigmoid(model(frames)) # Apply sigmoid for probabilities\n",
    "        # TODO Evaluate performance, like IOU or DICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training for Tracking\n",
    "\n",
    "# TODO Cloud\n",
    "# Make a new model in a new file\n",
    "# Train it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing for Tracking\n",
    "\n",
    "# TODO Cloud\n",
    "# Test the new model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
